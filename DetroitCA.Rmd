---
title: "Detroit Metro Land Cover Change Modeled by Cellular Automata"
author: "K. Arthur Endsley"
date: 'Sunday, November 23, 2014'
output:
  html_document:
    toc: yes
  pdf_document:
    toc: yes
---

```{r preamble, warning=FALSE, message=FALSE, results=FALSE}
library(sp, raster)
library(rgdal)
library(plyr, reshape2)
library(bnlearn)

setwd('/usr/local/dev/rdetroit/')
options(stringsAsFactors=FALSE)
```

# Methodology

1. Aggregate and stack predictor variables as rasters.
2. In a CA simulation...
  - For each pixel, pick one of the land cover values based on its probability

# Preparation

## Land Cover Data

We'll try aggregating the data to 90 meters to see if that gives us a feasible grid with which to work.

```{r}
file.loc <- '/home/arthur/Workspace/TermProject/'

require(raster)
rast2001 <- raster::raster(paste0(file.loc, 'nlcd2001_nad83.tif'))
rast2006 <- raster::raster(paste0(file.loc, 'nlcd2006_nad83.tif'))
reclass.matrix <- matrix(c(c(0,10,0), c(10,11,NA), c(12,20,0),
                           c(20,23,1), c(23,24,2), c(24,99,0)),
                         byrow=TRUE, ncol=3)
dev2001 <- raster::reclassify(rast2001, reclass.matrix, right=TRUE) # Intervals closed on right
dev2006 <- raster::reclassify(rast2006, reclass.matrix, right=TRUE)
```

```{r}
plot(dev2001); title('2001 Development Intensity at 30 meters')
```

```{r}
counties <- readOGR(paste0(file.loc, 'ancillary/co26_d00_select_nad83.shp'),
                    'co26_d00_select_nad83')
counties <- spTransform(counties, crs(dev2001))

plot(counties, col='#EEEEEE')
plot(dev2006 - dev2001, breaks=c(-2, -1, 0, 2), add=TRUE,
     col=c('#77DD00', '#FFFFFF00', '#113355'))
title('Change in Metro Detroit Development, 2001-2006')
```

We'll first aggregate the land cover data to 300 meters.

```{r}
dev2001 <- aggregate(dev2001, fact=10, fun=modal)
dev2006 <- aggregate(dev2006, fact=10, fun=modal)
save(dev2001, dev2006, file='rda/caAggregates.rda')
```

```{r}
plot(dev2001); title('2001 Development Intensity at 300 meters')
```

## Landscape and Census Data

We'll grab the other spatial data we created when training the Bayesian network.

```{r}
file.loc <- '/home/arthur/Workspace/TermProject/'
load(file='rda/spatialMeasures.rda')
load(file='rda/caAggregates.rda') # Replace dev2001 and dev2006 with aggregated

# Recreation and outdoor areas
rec.area.dist <- raster::raster(paste0(file.loc,
                                       'ancillary/rec+outdoor_nad83_prox_cut.tiff'))
rec.area.dist <- resample(rec.area.dist, dev2001)
```

## Rasterizing

```{r}
vars <- c('med.hhold.income', 'male.pop')
layers <- as.list(1:length(vars))
names(layers) <- vars
layers$old <- as.factor(dev2001)
layers$rec.area.proximity <- rec.area.dist

for (var in vars) {
  layers[var] <- rasterize(attr2006, dev2006, var)
}

save(layers, file='rda/layers.rda')
load(file='rda/layers.rda')
```

## Masking and Discretizing

First, we want to mask out the pixels outside of the census tracts.

```{r}
layers$old <- raster::mask(dev2001, layers$male.pop, maskvalue=NA)
layers$rec.area.proximity <- raster::mask(layers$rec.area.proximity,
                                          layers$male.pop, maskvalue=NA)
```

Next, we must discretize all the census and landscape layers.

```{r}
load(file='rda/graphs.rda')

training.sample <- data.frame(training.sample)

# Create a reclass matrix from the levels
vars <- c('rec.area.proximity', 'med.hhold.income', 'male.pop')
for (var in vars) {
  # Split apart e.g. "(20.1,190]"
  reclass.matrix <- sapply(levels(training.sample[,var]),
                           function (s) as.numeric(unlist(strsplit(gsub('\\[|\\]|\\(|\\)',
                                                                        '', s), ','))))
  reclass.matrix[1] <- 0
  layers[var] <- raster::reclassify(get(var, layers),
                                    cbind(reclass.matrix, c(0, 1)),
                                    right=TRUE) # Intervals closed on right
}
```

## Stacking

```{r}
layers <- stack(layers)

# TODO An improvement would be to have the levels of the layers be in [0, 1, 2, ...]
layer.levels <- list(rec.area.proximity=levels(training.sample$rec.area.proximity),
                     med.hhold.income=levels(training.sample$med.hhold.income),
                     male.pop=levels(training.sample$male.pop))

save(layers, layer.levels, file='rda/layerStack.rda')
load(file='rda/layerStack.rda')

# Clean-up
remove(var, vars, rec.area.dist, roads.dist, reclass.matrix)
```

We can see from the min and max values in the following output that all of our layers have been discretized.

```{r}
layers
```

# Examining the Network

```{r}
# TODO An improvement would be to have the levels of the layers be in [0, 1, 2, ...]
layer.levels <- list(rec.area.proximity=levels(training.sample$rec.area.proximity),
                     med.hhold.income=levels(training.sample$med.hhold.income),
                     male.pop=levels(training.sample$male.pop))

# A function to update the posterior probability distribution with evidence
updateNetwork <- function (jtree, states) {
  # Do not do anything if the input data are all NA
  if (all(is.na(states))) {
    return(jtree)
  }
  
  evidence <- transform(states,
                     med.hhold.income=layer.levels$med.hhold.income[med.hhold.income + 1],
                     male.pop=layer.levels$male.pop[male.pop + 1],
                     rec.area.proximity=layer.levels$rec.area.proximity[rec.area.proximity + 1],
                     old=as.character(old))
  
  for (i in seq(1, dim(evidence)[1])) {
    jtree <- setEvidence(jtree, nodes=names(evidence), nslist=mapply(list, evidence[i,]))
  }
  
  jtree
}

# A function to choose outcomes, one at a time, with the same probability as the given posterior distribution
chooseOutcome <- function (posterior) {
  posterior <- sort(posterior)
  
  # Sort the posterior probabilties by factors, e.g. "1=0.56,0=0.44" becomes "0=0.44,1=0.56"
  post <- numeric()
  for (i in seq.int(1, length(posterior))) {
    post[i] <- posterior[as.character(i - 1)]
  }
  
  # Generate a vector of probability thresholds e.g. [0.0, 0.44] for transitions to [0, 1]; upper bound of p=1.0 is implied.
  prob <- rep(0, length(post))
  for (i in seq.int(length(post) - 1, 1, by=-1)) {
    j <- length(post) - i
    prob <- prob + c(rep(0, j), post[(j-1):(length(post)-j)])
  }
  
  # Generate a random uniform deviate on [0, 1] to determine which factor to output
  r <- runif(1)
  for (i in seq.int(0, length(prob) - 2)) {
    if (r < prob[i + 2]) {
      return(i) # p < threshold in e.g. [0, 0.44]? Output that factor
    }
  }
  
  (length(prob) - 1) # p < implied upper bound of 1.0? Output last factor
}
```

Does our function reproduce classes with the same proportion as in the probability distribution?

```{r}
load(file='rda/graphs.rda')

require(gRain)
prior <- compile(as.grain(fit.expert))

foo <- querygrain(prior, nodes='new')$new
bar <- c()
for (i in seq(1, 10000)) { bar <- c(bar, chooseOutcome(foo)) }
a <- c('0'=length(bar[bar==0])/length(bar), '1'=length(bar[bar==1])/length(bar), '2'=length(bar[bar==2])/length(bar))
b <- c(foo['0'], foo['1'], foo['2'])

a; b
a - b
```

This function should be idempotent under any arbitary ordering of the input.

```{r}
foo <- querygrain(prior, nodes='new')$new
sort(foo)
bar <- c()
for (i in seq(1, 10000)) { bar <- c(bar, chooseOutcome(foo)) }
a <- c('0'=length(bar[bar==0])/length(bar), '1'=length(bar[bar==1])/length(bar), '2'=length(bar[bar==2])/length(bar))
b <- c(foo['0'], foo['1'], foo['2'])

a; b
a - b

remove(a, b, foo, bar, i)
```

```{r message=FALSE, warning=FALSE}
load(file='rda/graphs.rda')
load(file='rda/layerStack.rda')

require(gRain)

# We use the junction tree algorithm to create an independence network that we can query
prior <- compile(as.grain(fit.expert))

# Get the prior probabilities for new land cover
querygrain(prior, nodes='new')$new

# Update the posterior
posterior <- updateNetwork(prior, getValues(layers, 1, 1))

# Get the posterior probabilities for new land cover
querygrain(posterior, nodes='new')$new
```

# Simulation

```{r message=FALSE, warning=FALSE}
load(file='rda/graphs.rda')
load(file='rda/layerStack.rda')

require(gRain)

# We use the junction tree algorithm to create an independence network that we can query
prior.expert <- compile(as.grain(fit.expert))
prior.mmhc <- compile(as.grain(fit.mmhc))

# Both approaches, calc() and stackApply(), take the same amount of time
# output <- raster::calc(layers, function (states) {
#   apply(states, 1, function (r) {
#     chooseOutcome(querygrain(updateNetwork(prior.expert, as.data.frame(t(r))),
#                              nodes='new')$new)
#   })
# }, forcefun=TRUE)

output.expert.2006 <- stackApply(layers, rep(1, length(names(layers))), function (r, ...) {
  chooseOutcome(querygrain(updateNetwork(prior.expert, as.data.frame(t(r))),
                           nodes='new')$new)
})

output.mmhc.2006 <- stackApply(layers, rep(1, length(names(layers))), function (r, ...) {
  chooseOutcome(querygrain(updateNetwork(prior.mmhc, as.data.frame(t(r))),
                           nodes='new')$new)
})

output.mmhc.2006 <- mask(output.mmhc.2006, layers$male.pop, maskvalue=NA)
output.expert.2006 <- mask(output.expert.2006, layers$male.pop, maskvalue=NA)

save(output.mmhc.2006, output.expert.2006, file='rda/outputs2006.rda')
load(file='rda/outputs2006.rda')
```

What does our actual 2006 land cover look like?

```{r}
load(file='rda/caAggregates.rda')
file.loc <- '/home/arthur/Workspace/TermProject/'
counties <- readOGR(paste0(file.loc, 'ancillary/co26_d00_select_nad83.shp'),
                    'co26_d00_select_nad83')
counties <- spTransform(counties, crs(dev2001))

dev2006 <- mask(dev2006, layers$male.pop, maskvalue=NA)
cols <- c('#FFFFFF', '#AACCEE', '#113355')

plot(dev2006, axes=FALSE, box=FALSE, col=cols, legend=FALSE)
legend('bottomright', legend=c('High Development', 'Low Development', 'Undeveloped'),
       fill=rev(cols), bty="n", title='Land Cover', cex=1.3)
plot(counties, col='#EEEEEE00', lwd=1, add=TRUE)
title('2006 Observed Land Cover from NLCD')
# dev.copy(png, '~/Workspace/TermProject/outputs/graphics/plot_2006_observed_from_nlcd.png'); dev.off()
```

What does our "expert" prediction of 2006 land cover look like?

```{r}
cols <- c('#FFFFFF', '#AACCEE', '#113355')
```

```{r}
plot(output.expert.2006, axes=FALSE, box=FALSE, col=cols, legend=FALSE)
legend('bottomright', legend=c('High Development', 'Low Development', 'Undeveloped'),
       fill=rev(cols), bty="n", title='Land Cover', cex=1.3)
plot(counties, col='#EEEEEE00', lwd=1, add=TRUE)
title('2006 Prediction from Expert Graph with 2006 Census Data')
# dev.copy(png, '~/Workspace/TermProject/outputs/graphics/plot_2006_expert_prediction.png'); dev.off()
```

What does our "learned" prediction of 2006 land cover look like?

```{r}
plot(output.mmhc.2006, axes=FALSE, box=FALSE, col=cols, legend=FALSE)
legend('bottomright', legend=c('High Development', 'Low Development', 'Undeveloped'),
       fill=rev(cols), bty="n", title='Land Cover', cex=1.3)
plot(counties, col='#EEEEEE00', lwd=1, add=TRUE)
title('2006 Prediction from Learned Graph with 2006 Census Data')
# dev.copy(png, '~/Workspace/TermProject/outputs/graphics/plot_2006_learned_prediction.png'); dev.off()
```

How does each prediction compare to the observed data?

```{r}
require(RColorBrewer)
cols <- brewer.pal(3, 'RdBu')
cols[2] <- '#000000'

plot(dev2006 - output.expert.2006, axes=FALSE, box=FALSE, col=c(cols[1], cols, cols[3]),
     legend=FALSE)
legend('bottomright', legend=c('Overestimated', 'Agreement', 'Underestimated'),
       fill=cols, bty="n", title='Development Prediction', cex=1.3)
title('2006 Expert Graph Prediction Subtracted from Observed Land Cover')
# dev.copy(png, '~/Workspace/TermProject/outputs/graphics/plot_2006_observed_minus_expert.png'); dev.off()
```

```{r}
plot(dev2006 - output.mmhc.2006, axes=FALSE, box=FALSE, col=c(cols[1], cols, cols[3]),
     legend=FALSE)
legend('bottomright', legend=c('Overestimated', 'Agreement', 'Underestimated'),
       fill=cols, bty="n", title='Development Prediction', cex=1.3)
title('2006 Learned Graph Prediction Subtracted from Observed Land Cover')
# dev.copy(png, '~/Workspace/TermProject/outputs/graphics/plot_2006_observed_minus_learned.png'); dev.off()
```

Comparing the two differences to one another allows us to examine systematic bias in our model. Both the learned and the expert networks fail to predict high enough development in the same areas just outside the urban core. In addition, each network overestimates outlying (suburban) development in different areas. This indicates that the stochasticity in development predictions far from the urban core is too high while there is not a component in our model that accurately predicts development in a few, specific areas just outside the urban core.

And how do the predictions compare to each other?

```{r}
plot(output.expert.2006 - output.mmhc.2006, axes=FALSE, box=FALSE, col=c(cols[1], cols, cols[3]),
     legend=FALSE)
legend('bottomright', legend=c('Expert Prediction', 'Agreement', 'Learned Prediction'),
       fill=rev(cols), bty="n", title='Extra Development', cex=1.3)
title('2006 Expert Graph Prediction Subtracted from Learned Graph Prediction')
# dev.copy(png, '~/Workspace/TermProject/outputs/graphics/plot_2006_expert_minus_learned.png'); dev.off()
```

## Transition Probabilities

```{r}
# Figure out the order of the factors returned from the prior distribution (it isn't guaranteed to be in a predictable order); this is the order of the layers in the transition probabilties RasterStack
labels <- c('0'='prob.undeveloped', '1'='prob.low.dev', '2'='prob.high.dev')
labels. <- c()
for (l in names(querygrain(prior, nodes='new')$new)) {
  labels. <- c(labels., labels[as.numeric(l) + 1])
}

# Find transition probabilities for the expert graph
trans.probs.expert <- raster::calc(layers, function (states) {
  trans <- matrix(nrow=dim(states)[1], ncol=3)
  for (i in seq(1, dim(states)[1])) {
    trans[i,] <- querygrain(updateNetwork(prior, as.data.frame(t(states[i,]))),
                            nodes='new')$new
  }
  return(trans)
}, forcefun=TRUE)
names(trans.probs.expert) <- labels.

# Masking
trans.probs.expert$prob.undeveloped <- mask(trans.probs.expert$prob.undeveloped,
                                          layers$male.pop, maskvalue=NA)
trans.probs.expert$prob.low.dev <- mask(trans.probs.expert$prob.low.dev,
                                      layers$male.pop, maskvalue=NA)
trans.probs.expert$prob.high.dev <- mask(trans.probs.expert$prob.high.dev,
                                       layers$male.pop, maskvalue=NA)
```

```{r}
# Find transition probabilities for the learned graph
trans.probs.mmhc <- raster::calc(layers, function (states) {
  trans <- matrix(nrow=dim(states)[1], ncol=3)
  for (i in seq(1, dim(states)[1])) {
    trans[i,] <- querygrain(updateNetwork(prior.mmhc, as.data.frame(t(states[i,]))),
                            nodes='new')$new
  }
  return(trans)
}, forcefun=TRUE)
names(trans.probs.mmhc) <- labels.

# Masking
trans.probs.mmhc$prob.undeveloped <- mask(trans.probs.mmhc$prob.undeveloped,
                                          layers$male.pop, maskvalue=NA)
trans.probs.mmhc$prob.low.dev <- mask(trans.probs.mmhc$prob.low.dev,
                                      layers$male.pop, maskvalue=NA)
trans.probs.mmhc$prob.high.dev <- mask(trans.probs.mmhc$prob.high.dev,
                                       layers$male.pop, maskvalue=NA)


save(trans.probs.mmhc, trans.probs.expert, file='rda/transitionProbs.rda')
load(file='rda/transitionProbs.rda')
```

### Expert Graph Transition Probabilities

Now let's visualize these transition probabilities.

```{r}
load(file='rda/caAggregates.rda')
file.loc <- '/home/arthur/Workspace/TermProject/'
counties <- readOGR(paste0(file.loc, 'ancillary/co26_d00_select_nad83.shp'),
                    'co26_d00_select_nad83')
counties <- spTransform(counties, crs(dev2001))

require(RColorBrewer)
cols <- brewer.pal(5, 'PuBuGn')
cols[1] <- '#FFFFFF'

image(trans.probs.expert$prob.undeveloped, bty='n', zlim=c(0, 1),
      xlab='Easting (meters)', ylab='Northing (meters)',
      col=cols, breaks=seq(0, 1, by=0.2))
legend('bottomright', fill=rev(cols), bty="n", title='Prob. Undeveloped', cex=1.3,
       legend=c('0.8 - 1.0', '0.6 - 0.8', '0.4 - 0.6', '0.2 - 0.4', '0 - 0.2'))
plot(counties, col='#EEEEEE00', lwd=1, add=TRUE)
title('2006 Expert Graph Transition Probabilities: Undeveloped')
# dev.copy(png, '~/Workspace/TermProject/outputs/graphics/plot_2006_expert_trans_probs_undeveloped.png'); dev.off()
```

```{r}
image(trans.probs.expert$prob.low.dev, bty='n', zlim=c(0, 1),
      xlab='Easting (meters)', ylab='Northing (meters)',
      col=cols, breaks=seq(0, 1, by=0.2))
legend('bottomright', fill=rev(cols), bty="n", title='Prob. Low Dev.', cex=1.3,
       legend=c('0.8 - 1.0', '0.6 - 0.8', '0.4 - 0.6', '0.2 - 0.4', '0 - 0.2'))
plot(counties, col='#EEEEEE00', lwd=1, add=TRUE)
title('2006 Expert Graph Transition Probabilities: Low Development')
# dev.copy(png, '~/Workspace/TermProject/outputs/graphics/plot_2006_expert_trans_probs_lowdev.png'); dev.off()
```

```{r}
image(trans.probs.expert$prob.high.dev, bty='n', zlim=c(0, 1),
      xlab='Easting (meters)', ylab='Northing (meters)',
      col=cols, breaks=seq(0, 1, by=0.2))
legend('bottomright', fill=rev(cols), bty="n", title='Prob. High Dev.', cex=1.3,
       legend=c('0.8 - 1.0', '0.6 - 0.8', '0.4 - 0.6', '0.2 - 0.4', '0 - 0.2'))
plot(counties, col='#EEEEEE00', lwd=1, add=TRUE)
title('2006 Expert Graph Transition Probabilities: High Development')
# dev.copy(png, '~/Workspace/TermProject/outputs/graphics/plot_2006_expert_trans_probs_highdev.png'); dev.off()
```

### Learned Graph Transition Probabilities

```{r}
image(trans.probs.mmhc$prob.undeveloped, bty='n', zlim=c(0, 1),
      xlab='Easting (meters)', ylab='Northing (meters)',
      col=cols, breaks=seq(0, 1, by=0.2))
legend('bottomright', fill=rev(cols), bty="n", title='Prob. Undeveloped', cex=1.3,
       legend=c('0.8 - 1.0', '0.6 - 0.8', '0.4 - 0.6', '0.2 - 0.4', '0 - 0.2'))
plot(counties, col='#EEEEEE00', lwd=1, add=TRUE)
title('2006 Learned Graph Transition Probabilities: Undeveloped')
# dev.copy(png, '~/Workspace/TermProject/outputs/graphics/plot_2006_learned_trans_probs_undeveloped.png'); dev.off()
```

```{r}
image(trans.probs.mmhc$prob.low.dev, bty='n', zlim=c(0, 1),
      xlab='Easting (meters)', ylab='Northing (meters)',
      col=cols, breaks=seq(0, 1, by=0.2))
legend('bottomright', fill=rev(cols), bty="n", title='Prob. Low Dev.', cex=1.3,
       legend=c('0.8 - 1.0', '0.6 - 0.8', '0.4 - 0.6', '0.2 - 0.4', '0 - 0.2'))
plot(counties, col='#EEEEEE00', lwd=1, add=TRUE)
title('2006 Learned Graph Transition Probabilities: Low Development')
# dev.copy(png, '~/Workspace/TermProject/outputs/graphics/plot_2006_learned_trans_probs_lowdev.png'); dev.off()
```

```{r}
image(trans.probs.mmhc$prob.high.dev, bty='n', zlim=c(0, 1),
      xlab='Easting (meters)', ylab='Northing (meters)',
      col=cols, breaks=seq(0, 1, by=0.2))
legend('bottomright', fill=rev(cols), bty="n", title='Prob. High Dev.', cex=1.3,
       legend=c('0.8 - 1.0', '0.6 - 0.8', '0.4 - 0.6', '0.2 - 0.4', '0 - 0.2'))
plot(counties, col='#EEEEEE00', lwd=1, add=TRUE)
title('2006 Learned Graph Transition Probabilities: High Development')
# dev.copy(png, '~/Workspace/TermProject/outputs/graphics/plot_2006_learned_trans_probs_highdev.png'); dev.off()
```

### Comparing Transition Probabilities

Comparing transition probabilties between the two graphs provides further insight into the model's function. While there are some noticeable differences in the transition probabilities for low- and no-development, there are only very small differences between the transition probabilities in each graph for high development. Alternatively, it can be said that the high-development transition map has less variance than the others.

```{r}
require(RColorBrewer)
cols <- brewer.pal(5, 'RdYlBu')
cols <- c(cols[1], cols[1], '#FFFFFF', cols[5], cols[5])

image(trans.probs.expert$prob.high.dev - trans.probs.mmhc$prob.high.dev, col=cols,
      breaks=seq(-0.1, 0.1, by=0.04), bty='n')
legend('bottomright', fill=rev(c(cols[1], cols[3], cols[5])),
       bty="n", title='Prob. High Dev.', cex=1.3,
       legend=c("Expert Prediction", "Near Agreement", "Learned Prediction"))
plot(counties, col='#EEEEEE00', lwd=1, add=TRUE)
title('2006 High-Dev. Transition Probabilities: Expert Minus Learned')
```

```{r}
par(mfrow=c(2,2))
hist(trans.probs.expert$prob.undeveloped - trans.probs.mmhc$prob.undeveloped,
     main='Probability Undeveloped', breaks=seq(-0.2, 0.2, by=0.01))
hist(trans.probs.expert$prob.low.dev - trans.probs.mmhc$prob.low.dev,
     main='Probability Low-Development', breaks=seq(-0.2, 0.2, by=0.01))
hist(trans.probs.expert$prob.high.dev - trans.probs.mmhc$prob.high.dev,
     main='Probability High-Development', breaks=seq(-0.2, 0.2, by=0.01))
```

# Validation

```{r}
load(file='rda/caAggregates.rda') # Replace dev2001 and dev2006 with aggregated
dev2006 <- mask(dev2006, output.expert.2006, maskvalue=NA)

# cols <- c('#FFFFFF', '#AACCEE', '#113355')
# plot(output.mmhc.2006, axes=FALSE, box=FALSE, col=cols, legend=FALSE)
pts <- as.data.frame(output.expert.2006, xy=TRUE)
pts$layer <- NULL
# points(pts, col='red')

stats <- data.frame(matrix(nrow=3, ncol=5), row.names=c('observed', 'expert', 'learned'))
names(stats) <- c('Cohens.Kappa', 'Undev.freq', 'Low.dev.freq', 'High.dev.freq', 'Compactness')

require(raster)
samples.observed <- extract(dev2006, pts, df=TRUE, factors=TRUE)
samples.mmhc.2006 <- extract(output.mmhc.2006, pts, df=TRUE, factors=TRUE)
samples.expert.2006 <- extract(output.expert.2006, pts, df=TRUE, factors=TRUE)
```

## Agreement with Observed

What is the agreement between the expert prediction and the observed?

```{r}
require(lpSolve, irr)
stats['expert', 'Cohens.Kappa'] <- kappa2(data.frame(actual=samples.observed$layer,
                                                     guess=samples.expert.2006$layer))$value
stats['learned', 'Cohens.Kappa'] <- kappa2(data.frame(actual=samples.observed$layer,
                                                      guess=samples.mmhc.2006$layer))$value
```

## Class Frequencies

```{r}
stats['observed', 'Undev.freq'] <- count(samples.observed, 'layer')[1,]$freq
stats['observed', 'Low.dev.freq'] <- count(samples.observed, 'layer')[2,]$freq
stats['observed', 'High.dev.freq'] <- count(samples.observed, 'layer')[3,]$freq
stats['learned', 'Undev.freq'] <- count(samples.mmhc.2006, 'layer')[1,]$freq
stats['learned', 'Low.dev.freq'] <- count(samples.mmhc.2006, 'layer')[2,]$freq
stats['learned', 'High.dev.freq'] <- count(samples.mmhc.2006, 'layer')[3,]$freq
stats['expert', 'Undev.freq'] <- count(samples.expert.2006, 'layer')[1,]$freq
stats['expert', 'Low.dev.freq'] <- count(samples.expert.2006, 'layer')[2,]$freq
stats['expert', 'High.dev.freq'] <- count(samples.expert.2006, 'layer')[3,]$freq
```



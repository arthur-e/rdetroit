---
title: "Detroit Metro Land Cover Change Modeled by Cellular Automata"
author: "K. Arthur Endsley"
date: 'Sunday, November 23, 2014'
output:
  html_document:
    toc: yes
  pdf_document:
    toc: yes
---

```{r preamble, warning=FALSE, message=FALSE, results=FALSE}
library(sp, raster)
library(rgdal)
library(plyr, reshape2)
library(bnlearn)

setwd('/usr/local/dev/rdetroit/')
options(stringsAsFactors=FALSE)
```

# Methodology

1. Aggregate and stack predictor variables as rasters.
2. In a CA simulation...
  - For each pixel, pick one of the land cover values based on its probability

# Preparation

## Land Cover Data

We'll try aggregating the data to 90 meters to see if that gives us a feasible grid with which to work.

```{r}
file.loc <- '/home/arthur/Workspace/TermProject/'

require(raster)
rast2001 <- raster::raster(paste0(file.loc, 'nlcd2001_nad83.tif'))
rast2006 <- raster::raster(paste0(file.loc, 'nlcd2006_nad83.tif'))
reclass.matrix <- matrix(c(c(0,10,0), c(10,11,NA), c(12,20,0),
                           c(20,23,1), c(23,24,2), c(24,99,0)),
                         byrow=TRUE, ncol=3)
dev2001 <- raster::reclassify(rast2001, reclass.matrix, right=TRUE) # Intervals closed on right
dev2006 <- raster::reclassify(rast2006, reclass.matrix, right=TRUE)
```

```{r}
plot(dev2001); title('2001 Development Intensity at 30 meters')
```

```{r}
counties <- readOGR(paste0(file.loc, 'ancillary/co26_d00_select_nad83.shp'),
                    'co26_d00_select_nad83')
counties <- spTransform(counties, crs(dev2001))

plot(counties, col='#EEEEEE')
plot(dev2006 - dev2001, breaks=c(-2, -1, 0, 2), add=TRUE,
     col=c('#77DD00', '#FFFFFF00', '#113355'))
title('Change in Metro Detroit Development, 2001-2006')
```

We'll first aggregate the land cover data to 300 meters.

```{r}
dev2001 <- aggregate(dev2001, fact=10, fun=modal)
dev2006 <- aggregate(dev2006, fact=10, fun=modal)
save(dev2001, dev2006, file='rda/caAggregates.rda')
```

```{r}
plot(dev2001); title('2001 Development Intensity at 300 meters')
```

## Landscape and Census Data

We'll grab the other spatial data we created when training the Bayesian network.

```{r}
file.loc <- '/home/arthur/Workspace/TermProject/'
load(file='rda/spatialMeasures.rda')
load(file='rda/caAggregates.rda') # Replace dev2001 and dev2006 with aggregated

# Recreation and outdoor areas
rec.area.dist <- raster::raster(paste0(file.loc,
                                       'ancillary/rec+outdoor_nad83_prox_cut.tiff'))
rec.area.dist <- resample(rec.area.dist, dev2001)
```

## Rasterizing

```{r}
vars <- c('med.hhold.income', 'male.pop')
layers <- as.list(1:length(vars))
names(layers) <- vars
layers$old <- as.factor(dev2001)
layers$rec.area.proximity <- rec.area.dist

for (var in vars) {
  layers[var] <- rasterize(attr2006, dev2006, var)
}

save(layers, file='rda/layers.rda')
load(file='rda/layers.rda')
```

## Masking and Discretizing

First, we want to mask out the pixels outside of the census tracts.

```{r}
layers$old <- raster::mask(dev2001, layers$male.pop, maskvalue=NA)
layers$rec.area.proximity <- raster::mask(layers$rec.area.proximity,
                                          layers$male.pop, maskvalue=NA)
```

Next, we must discretize all the census and landscape layers.

```{r}
load(file='rda/graphs.rda')

training.sample <- data.frame(training.sample)

# Create a reclass matrix from the levels
vars <- c('rec.area.proximity', 'med.hhold.income', 'male.pop')
for (var in vars) {
  # Split apart e.g. "(20.1,190]"
  reclass.matrix <- sapply(levels(training.sample[,var]),
                           function (s) as.numeric(unlist(strsplit(gsub('\\[|\\]|\\(|\\)',
                                                                        '', s), ','))))
  reclass.matrix[1] <- 0
  layers[var] <- raster::reclassify(get(var, layers),
                                    cbind(reclass.matrix, c(0, 1)),
                                    right=TRUE) # Intervals closed on right
}
```

## Stacking

```{r}
layers <- stack(layers)

# TODO An improvement would be to have the levels of the layers be in [0, 1, 2, ...]
layer.levels <- list(rec.area.proximity=levels(training.sample$rec.area.proximity),
                     med.hhold.income=levels(training.sample$med.hhold.income),
                     male.pop=levels(training.sample$male.pop))

save(layers, layer.levels, file='rda/layerStack.rda')
load(file='rda/layerStack.rda')

# Clean-up
remove(var, vars, rec.area.dist, roads.dist, reclass.matrix)
```

We can see from the min and max values in the following output that all of our layers have been discretized.

```{r}
layers
```

# Examining the Network

```{r}
# TODO An improvement would be to have the levels of the layers be in [0, 1, 2, ...]
layer.levels <- list(rec.area.proximity=levels(training.sample$rec.area.proximity),
                     med.hhold.income=levels(training.sample$med.hhold.income),
                     male.pop=levels(training.sample$male.pop))

# A function to update the posterior probability distribution with evidence
updateNetwork <- function (jtree, states) {
  # Do not do anything if the input data are all NA
  if (all(is.na(states))) {
    return(jtree)
  }
  
  evidence <- transform(states,
                     med.hhold.income=layer.levels$med.hhold.income[med.hhold.income + 1],
                     male.pop=layer.levels$male.pop[male.pop + 1],
                     rec.area.proximity=layer.levels$rec.area.proximity[rec.area.proximity + 1],
                     old=as.character(old))
  
  for (i in seq(1, dim(evidence)[1])) {
    jtree <- setEvidence(jtree, nodes=names(evidence), nslist=mapply(list, evidence[i,]))
  }
  
  jtree
}

# A function to choose outcomes, one at a time, with the same probability as the given posterior distribution
chooseOutcome <- function (posterior) {
  posterior <- sort(posterior)
  
  # Sort the posterior probabilties by factors, e.g. "1=0.56,0=0.44" becomes "0=0.44,1=0.56"
  post <- numeric()
  for (i in seq.int(1, length(posterior))) {
    post[i] <- posterior[as.character(i - 1)]
  }
  
  # Generate a vector of probability thresholds e.g. [0.0, 0.44] for transitions to [0, 1]; upper bound of p=1.0 is implied.
  prob <- rep(0, length(post))
  for (i in seq.int(length(post) - 1, 1, by=-1)) {
    j <- length(post) - i
    prob <- prob + c(rep(0, j), post[(j-1):(length(post)-j)])
  }
  
  # Generate a random uniform deviate on [0, 1] to determine which factor to output
  r <- runif(1)
  for (i in seq.int(0, length(prob) - 2)) {
    if (r < prob[i + 2]) {
      return(i) # p < threshold in e.g. [0, 0.44]? Output that factor
    }
  }
  
  (length(prob) - 1) # p < implied upper bound of 1.0? Output last factor
}
```

Does our function reproduce classes with the same proportion as in the probability distribution?

```{r}
load(file='rda/graphs.rda')

require(gRain)
prior <- compile(as.grain(fit.expert))

foo <- querygrain(prior, nodes='new')$new
bar <- c()
for (i in seq(1, 10000)) { bar <- c(bar, chooseOutcome(foo)) }
a <- c('0'=length(bar[bar==0])/length(bar), '1'=length(bar[bar==1])/length(bar), '2'=length(bar[bar==2])/length(bar))
b <- c(foo['0'], foo['1'], foo['2'])

a; b
a - b
```

This function should be idempotent under any arbitary ordering of the input.

```{r}
foo <- querygrain(prior, nodes='new')$new
sort(foo)
bar <- c()
for (i in seq(1, 10000)) { bar <- c(bar, chooseOutcome(foo)) }
a <- c('0'=length(bar[bar==0])/length(bar), '1'=length(bar[bar==1])/length(bar), '2'=length(bar[bar==2])/length(bar))
b <- c(foo['0'], foo['1'], foo['2'])

a; b
a - b

remove(a, b, foo, bar, i)
```

```{r message=FALSE, warning=FALSE}
load(file='rda/graphs.rda')
load(file='rda/layerStack.rda')

require(gRain)

# We use the junction tree algorithm to create an independence network that we can query
prior <- compile(as.grain(fit.expert))

# Get the prior probabilities for new land cover
querygrain(prior, nodes='new')$new

# Update the posterior
posterior <- updateNetwork(prior, getValues(layers, 1, 1))

# Get the posterior probabilities for new land cover
querygrain(posterior, nodes='new')$new
```

# Simulation

```{r message=FALSE, warning=FALSE}
load(file='rda/graphs.rda')
load(file='rda/layerStack.rda')

require(gRain)

# We use the junction tree algorithm to create an independence network that we can query
prior.expert <- compile(as.grain(fit.expert))
prior.mmhc <- compile(as.grain(fit.mmhc))

# Both approaches, calc() and stackApply(), take the same amount of time
# output <- raster::calc(layers, function (states) {
#   apply(states, 1, function (r) {
#     chooseOutcome(querygrain(updateNetwork(prior.expert, as.data.frame(t(r))),
#                              nodes='new')$new)
#   })
# }, forcefun=TRUE)

output.expert.2006 <- stackApply(layers, rep(1, length(names(layers))), function (r, ...) {
  chooseOutcome(querygrain(updateNetwork(prior.expert, as.data.frame(t(r))),
                           nodes='new')$new)
})

output.mmhc.2006 <- stackApply(layers, rep(1, length(names(layers))), function (r, ...) {
  chooseOutcome(querygrain(updateNetwork(prior.mmhc, as.data.frame(t(r))),
                           nodes='new')$new)
})

output.mmhc.2006 <- mask(output.mmhc.2006, layers$pop.density, maskvalue=NA)
output.expert.2006 <- mask(output.expert.2006, layers$pop.density, maskvalue=NA)

save(output.mmhc.2006, output.expert.2006, file='rda/outputs2006.rda')
load(file='rda/outputs2006.rda')
```

What does our actual 2006 land cover look like?

```{r}
load(file='rda/caAggregates.rda')
counties <- readOGR(paste0(file.loc, 'ancillary/co26_d00_select_nad83.shp'),
                    'co26_d00_select_nad83')
counties <- spTransform(counties, crs(dev2001))

dev2006 <- mask(dev2006, layers$pop.density, maskvalue=NA)
cols <- c('#FFFFFF', '#AACCEE', '#113355')

plot(dev2006, axes=FALSE, box=FALSE, col=cols, legend=FALSE)
legend('bottomright', legend=c('High Development', 'Low Development', 'Undeveloped'),
       fill=rev(cols), bty="n", title='Legend', cex=1.3)
plot(counties, col='#EEEEEE00', lwd=1, add=TRUE)
title('2006 Observed Land Cover from NLCD')
```

What does our "expert" prediction of 2006 land cover look like?

```{r}
cols <- c('#FFFFFF', '#AACCEE', '#113355')
```

```{r}
plot(output.expert.2006, axes=FALSE, box=FALSE, col=cols, legend=FALSE)
legend('bottomright', legend=c('High Development', 'Low Development', 'Undeveloped'),
       fill=rev(cols), bty="n", title='Land Cover', cex=1.3)
plot(counties, col='#EEEEEE00', lwd=1, add=TRUE)
title('2006 Prediction from Expert Graph with 2006 Census Data')
```

What does our "learned" prediction of 2006 land cover look like?

```{r}
plot(output.mmhc.2006, axes=FALSE, box=FALSE, col=cols, legend=FALSE)
legend('bottomright', legend=c('High Development', 'Low Development', 'Undeveloped'),
       fill=rev(cols), bty="n", title='Land Cover', cex=1.3)
plot(counties, col='#EEEEEE00', lwd=1, add=TRUE)
title('2006 Prediction from Learned Graph with 2006 Census Data')
```

How does each prediction compare to the observed data?

```{r}
require(RColorBrewer)
cols <- brewer.pal(3, 'RdBu')
cols[2] <- '#000000'

plot(dev2006 - output.expert.2006, axes=FALSE, box=FALSE, col=c(cols[1], cols, cols[3]),
     legend=FALSE)
legend('bottomright', legend=c('Commission', 'Agreement', 'Ommission'),
       fill=rev(cols), bty="n", title='Legend', cex=1.3)
title('2006 Expert Graph Prediction Subtracted from Observed Land Cover')
```

```{r}
plot(dev2006 - output.mmhc.2006, axes=FALSE, box=FALSE, col=c(cols[1], cols, cols[3]),
     legend=FALSE)
legend('bottomright', legend=c('Commission', 'Agreement', 'Ommission'),
       fill=rev(cols), bty="n", title='Legend', cex=1.3)
title('2006 Learned Graph Prediction Subtracted from Observed Land Cover')
```

And how do the predictions compare to each other?

```{r}
plot(output.expert.2006 - output.mmhc.2006, axes=FALSE, box=FALSE, col=c(cols[1], cols, cols[3]),
     legend=FALSE)
legend('bottomright', legend=c('Expert Prediction', 'Agreement', 'Learned Prediction'),
       fill=rev(cols), bty="n", title='Legend', cex=1.3)
title('2006 Expert Graph Prediction Subtracted from Learned Graph Prediction')
```

## Transition Probabilities

```{r}
# Find transition probabilities for the expert graph
trans.probs.expert <- raster::calc(layers, function (states) {
  trans <- matrix(nrow=dim(states)[1], ncol=3)
  for (i in seq(1, dim(states)[1])) {
    trans[i,] <- as.numeric(querygrain(updateNetwork(prior, as.data.frame(t(states[i,]))),
                                       nodes='new')$new)
  }
  return(trans)
}, forcefun=TRUE)
names(trans.probs.expert) <- c('prob.undeveloped', 'prob.low.dev', 'prob.high.dev')

# Masking
trans.probs.expert$prob.undeveloped <- mask(trans.probs.expert$prob.undeveloped,
                                          layers$pop.density, maskvalue=NA)
trans.probs.expert$prob.low.dev <- mask(trans.probs.expert$prob.low.dev,
                                      layers$pop.density, maskvalue=NA)
trans.probs.expert$prob.high.dev <- mask(trans.probs.expert$prob.high.dev,
                                       layers$pop.density, maskvalue=NA)
```

```{r}
# Find transition probabilities for the learned graph
trans.probs.mmhc <- raster::calc(layers, function (states) {
  trans <- matrix(nrow=dim(states)[1], ncol=3)
  for (i in seq(1, dim(states)[1])) {
    trans[i,] <- as.numeric(querygrain(updateNetwork(prior.mmhc, as.data.frame(t(states[i,]))),
                                       nodes='new')$new)
  }
  return(trans)
}, forcefun=TRUE)
names(trans.probs.mmhc) <- c('prob.undeveloped', 'prob.low.dev', 'prob.high.dev')

# Masking
trans.probs.mmhc$prob.undeveloped <- mask(trans.probs.mmhc$prob.undeveloped,
                                          layers$pop.density, maskvalue=NA)
trans.probs.mmhc$prob.low.dev <- mask(trans.probs.mmhc$prob.low.dev,
                                      layers$pop.density, maskvalue=NA)
trans.probs.mmhc$prob.high.dev <- mask(trans.probs.mmhc$prob.high.dev,
                                       layers$pop.density, maskvalue=NA)


save(trans.probs.mmhc, trans.probs.expert, file='rda/transitionProbs.rda')
load(file='rda/transitionProbs.rda')
```

```{r}
require(RColorBrewer)
cols <- brewer.pal(5, 'PuBuGn')
cols[1] <- '#FFFFFF'

image(trans.probs.expert$prob.undeveloped, axes=FALSE, zlim=c(0, 1),
      xlab='', ylab='', col=cols, breaks=seq(0, 1, by=0.2))
legend('bottomright', fill=rev(cols), bty="n", title='Prob. Undeveloped', cex=1.3,
       legend=c('0.8 - 1.0', '0.6 - 0.8', '0.4 - 0.6', '0.2 - 0.4', '0 - 0.2'))
plot(counties, col='#EEEEEE00', lwd=1, add=TRUE)
title('2006 Expert Graph Transition Probabilities: Undeveloped')

image(trans.probs.mmhc$prob.undeveloped, axes=FALSE, zlim=c(0, 1),
      xlab='', ylab='', col=cols, breaks=seq(0, 1, by=0.2))
legend('bottomright', fill=rev(cols), bty="n", title='Prob. Undeveloped', cex=1.3,
       legend=c('0.8 - 1.0', '0.6 - 0.8', '0.4 - 0.6', '0.2 - 0.4', '0 - 0.2'))
plot(counties, col='#EEEEEE00', lwd=1, add=TRUE)
title('2006 Learned Graph Transition Probabilities: Undeveloped')
```

```{r}
image(trans.probs.expert$prob.low.dev, axes=FALSE, zlim=c(0, 1),
      xlab='', ylab='', col=cols, breaks=seq(0, 1, by=0.2))
legend('bottomright', fill=rev(cols), bty="n", title='Prob. Low Dev.', cex=1.3,
       legend=c('0.8 - 1.0', '0.6 - 0.8', '0.4 - 0.6', '0.2 - 0.4', '0 - 0.2'))
plot(counties, col='#EEEEEE00', lwd=1, add=TRUE)
title('2006 Expert Graph Transition Probabilities: Low Development')

image(trans.probs.mmhc$prob.low.dev, axes=FALSE, zlim=c(0, 1),
      xlab='', ylab='', col=cols, breaks=seq(0, 1, by=0.2))
legend('bottomright', fill=rev(cols), bty="n", title='Prob. Low Dev.', cex=1.3,
       legend=c('0.8 - 1.0', '0.6 - 0.8', '0.4 - 0.6', '0.2 - 0.4', '0 - 0.2'))
plot(counties, col='#EEEEEE00', lwd=1, add=TRUE)
title('2006 Learned Graph Transition Probabilities: Low Development')
```

```{r}
image(trans.probs.expert$prob.high.dev, axes=FALSE, zlim=c(0, 1),
      xlab='', ylab='', col=cols, breaks=seq(0, 1, by=0.2))
legend('bottomright', fill=rev(cols), bty="n", title='Prob. High Dev.', cex=1.3,
       legend=c('0.8 - 1.0', '0.6 - 0.8', '0.4 - 0.6', '0.2 - 0.4', '0 - 0.2'))
plot(counties, col='#EEEEEE00', lwd=1, add=TRUE)
title('2006 Expert Graph Transition Probabilities: High Development')

image(trans.probs.mmhc$prob.high.dev, axes=FALSE, zlim=c(0, 1),
      xlab='', ylab='', col=cols, breaks=seq(0, 1, by=0.2))
legend('bottomright', fill=rev(cols), bty="n", title='Prob. High Dev.', cex=1.3,
       legend=c('0.8 - 1.0', '0.6 - 0.8', '0.4 - 0.6', '0.2 - 0.4', '0 - 0.2'))
plot(counties, col='#EEEEEE00', lwd=1, add=TRUE)
title('2006 Learned Graph Transition Probabilities: High Development')
```


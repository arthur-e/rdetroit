---
title: "Detroit Metro Land Cover Data"
author: "K. Arthur Endsley"
date: "Wednesday, November 05, 2014"
output: pdf_document
---

The intent is to learn the major drivers of land cover change in the Detroit Metro area from 2001 to 2006 and use the modeled relationships to predict land cover change in 2011.

# Data Sources

All dollar values were adjusted for inflation to 2010 values.

**Used in analysis:**
* [2000 and 2010 Census tract boundaries](http://semcog.org/MapCatalog_Demographic.aspx) - SEMCOG

**Alternatives:** 
* [2000 Census tract boundaries](http://www.mcgi.state.mi.us/mgdl/?rel=thext&action=thmname&cid=16&cat=2000+Tracts+from+MI+Geographic+Framework+%28v14a%29)
* [2010 Census tract boundaries](http://www.mcgi.state.mi.us/mgdl/?rel=thext&action=thmname&cid=16&cat=2010+Tracts+from+MI+Geographic+Framework+%28v14a%29) (Used for 2006 ACS as well)

## Potential SocialExplorer Census Measures

Variable names are given in parentheses as (2000 Census, American Community Survey).

* Population density (`SE_T003_001`, `SE_T002_001`)
* Median household income (`SE_T093_001`, `SE_T057_001`)

* Normalized by housing unit count (`SE_T155_001`, `SE_T093_001`)...
  * Occupied housing units (`SE_T156_001`, `SE_T094_001`)
  * Occupied housing units: owner occupied (`SE_T156_002`, `SE_T094_002`)

* Normalized by land area (`SE_T004_002`, `SE_T002_003`)...
  * Housing unit count (`SE_T155_001`, `SE_T093_001`)
  * Households (`SE_T020_001`, `SE_T017_001`)
  * Family households (`SE_T020_002`, `SE_T017_002`)
  * Married-couple households (`SE_T020_003`, `SE_T017_003`)
  * Family households with Male householder, no spouse present (`SE_T020_005`, `SE_T017_005`)
  * Family households with Female householder, no spouse present (`SE_T020_006`, `SE_T017_006`)
  * Non-family households with Male householder (`SE_T020_008`, `SE_T017_008`)
  * Non-family households with Female householder (`SE_T020_009`, `SE_T017_009`)
  
* Normalized by family household population (`SE_T025_003`, (None))...
  * Householders (`SE_T025_004`, (None))
  * Children in households (`SE_T025_006`, (None))
  * Grandchildren in households (`SE_T025_007`, (None))
  * Parents in households (`SE_T025_009`, (None))
  * Non-relatives in households (`SE_T025_011`, (None))
  
* Normalized by non-family household population (`SE_T025_012`, (None))...
  * Population living alone (`SE_T025_013`, (None))
  
* Normalized by total population (`SE_T025_001`, `SE_T001_001`)...
  * Male population (`SE_T005_002`, `SE_T004_002`)
  * Female population (`SE_T005_003`, `SE_T004_003`)
  * White population (`SE_T014_002`, `SE_T013_002`)
  * Black or African American population (`SE_T014_003`, `SE_T013_003`)
  * Asian population (`SE_T014_005`, `SE_T013_005`)
  * Population in group quarters (`SE_T025_016`, (None))
  * Population 16 years and over (`SE_T069_001`, (None))
  * Population poor or struggling (`SE_T185_004`, `SE_T118_004`)

* Normalized by population in group quarters (`SE_T025_016`, (None))...
  * Institutionalized population (`SE_T025_017`, (None))
  
* Normalized by population 16 years and over (`SE_T069_001`, (None))...
  * Population 16 and over in the labor force (`SE_T069_002`, (None))
  
* Normalized by population 16 and over in the labor force (`SE_T069_002`, (None))...
  * Employed civilians in the labor force (`SE_T069_005`, (None))

## U.S. Census

* [Decennial Census overview and 1990, 2000 datasets](http://www.census.gov/prod/www/decennial.html)
* [Maps and geographic data](http://www.census.gov/geo/maps-data/)

# Methodology

1. Interpolate 2000 Census data to 2010 Census tract boundaries.
2. Normalize 2000 Census and ACS 2006 measures.
  - Other measures? Distance to roads?
  - Slope?
  - Distance to [recreation and open space?](ftp://ftp.semcog.org/outgoing/web/landuse/regrec.zip)
3. Join census tract attributes to census tract boundaries.
4. Rasterize census tracts to NLCD grid.
5. Configure the Bayesian network's nodes; include land use drivers and future land use states (classes).
6. Learn the Bayesian network structure.
  - Intersect 2001 and 2006 land cover observations with the 2001 and 2006 census measures, respectively.
  - Compare learned network structure across constraint-based, score-based and hybrid structure learning algorithms.
  - Compare learned network structure for 2001 data (only) and 2006 data (only) using Bayes Information Criterion (`bnlearn::score()`).
  - Use random restarts and perturbation with the Hill Climbing algorithm to determine stability of learned and expert-specified network structures.
  - Learn network only on changed pixels from 2001 to 2006.
  - Construct random undirected graph.
  - Construct expert undirected graph.
  - Complete graphs by learning on undirected graphs.
7. Parameterize the nodes of the BN.
8. Assess predictions of BN in the absence of a CA model.
  - What is the nature of the BN predictions? Are they propagated from state variable observations?
  - If so, can we use the BN in absence of a CA to predict transition probabilities for each pixel in 2006, 2011?
  - Then, evaluate the effect of picking this threshold for each land cover class transition in 2006, 2011.
  - If we need a CA model to drive land comver changes, use simple rules from the SLEUTH model to propagate year-to-year changes stochastically based on the conditional probabilities.
9. Investigate the effect of monotonic changes in population density, medium household income, and (proportion) occupied housing on land cover.

## Dependencies

```{r installation, eval=FALSE}
install.packages(c('bnlearn', 'reshape2', 'plyr', 'ggplot2', 'sp', 'raster', 'rgdal'))
```

## Cross-Walking Census Data

From [U.S. 2010: Discover America in a New Century](http://www.s4.brown.edu/us2010/Researcher/ltdb3.htm): "The crosswalk identifies what portion of a tract in one year should be allocated to a 2010 tract. For every decennial year from 1970 to 2000, every row in the crosswalk lists a 2010 tract ID, the ID of a tract in the source year that contributes to it, and the share of the source tract's population attributes that should be allocated to the 2010 tract. In cases where there is an exact correspondence between the source tract and the 2010 tract, there is only one row of data for the 2010 tract. Otherwise there are as many rows as there are contributing tracts."

Reference to use is: "John R. Logan, Zengwang Xu, and Brian Stults. 2012. “Interpolating US Decennial Census Tract Data from as Early as 1970 to 2010: A Longitudinal Tract Database” Professional Geographer, forthcoming."

## Interpolating 2000 Census Tracts to 2010 Census Tracts

```{r preamble, warning=FALSE, results=FALSE, message=FALSE}
library(sp, raster)
library(rgdal)
```

```{r}
setwd('/home/arthur/Downloads')
options(stringsAsFactors=FALSE)

census.vars <- c('SE_T003_001', 'SE_T093_001', 'SE_T155_001', 'SE_T156_001', 'SE_T156_002', 'SE_T004_002', 'SE_T005_002', 'SE_T005_003', 'SE_T014_002', 'SE_T014_003', 'SE_T014_005', 'SE_T020_001', 'SE_T020_002', 'SE_T020_003', 'SE_T020_005', 'SE_T020_006', 'SE_T020_008', 'SE_T020_009', 'SE_T025_001', 'SE_T185_004')
acs.vars <- c('SE_T002_001', 'SE_T001_001', 'SE_T004_002', 'SE_T004_003', 'SE_T002_003', 'SE_T057_001', 'SE_T093_001', 'SE_T094_001', 'SE_T094_002', 'SE_T017_001', 'SE_T017_002', 'SE_T017_003', 'SE_T017_005', 'SE_T017_006', 'SE_T017_008', 'SE_T017_009', 'SE_T013_002', 'SE_T013_003', 'SE_T013_005', 'SE_T118_004')

census2000 <- read.csv('census2000.csv', header=T, skip=1,
                       colClasses=c('Geo_FIPS'='character')) # 2000 Census data
acs2006.2010 <- read.csv('acs2006-2010.csv', header=T, skip=1,
                       colClasses=c('Geo_FIPS'='character')) # 2006-2010 ACS data
tracts <- union(census2000$Census.Tract, acs2006.2010$Census.Tract)

require(plyr)
xwalk <- arrange(read.csv('crosswalk_2000_2010.csv', colClasses=c('character', 'character')),
                 trtid10) # 2000 to 2010 Crosswalk data
xwalk <- within(xwalk, weight <- as.numeric(weight))

require(plyr)
census2000 <- subset(mutate(census2000, trtid00=Geo_FIPS), select=c('trtid00', census.vars))
acs2006.2010 <- subset(acs2006.2010, select=c('Geo_FIPS', acs.vars))

# Subset the crosswalk table to just those tracts in our census data
xwalk <- subset(xwalk, trtid00 %in% intersect(census2000$trtid00, xwalk$trtid00),
                select=c(trtid00, trtid10, weight))

# We interpolate the 2000 census tracts to 2010 census tracts by a weighted linear combination
require(reshape2)
temp <- melt(join(xwalk, census2000, by=c('trtid00')),
            id.vars=c('trtid00', 'trtid10', 'weight'))
temp <- within(temp, value <- value * weight) # Scale the census measures by Brown et al.'s weights

# Recast 2010 census tracts as a sum of the 2000 census measures
census2000.as.2010 <- within(dcast(temp, trtid10 ~ variable, fun.aggregate=sum, value.var='value'),
                             Geo_FIPS <- trtid10)

# For some reason, a couple of tracts in the ACS are not in the 2010 interpolation of the 2000 census
disjoint.tracts <- union(setdiff(census2000.as.2010$Geo_FIPS, acs2006.2010$Geo_FIPS),
                         setdiff(acs2006.2010$Geo_FIPS, census2000.as.2010$Geo_FIPS))

acs2006.2010 <- subset(acs2006.2010, !Geo_FIPS %in% disjoint.tracts)
census2000.as.2010 <- subset(census2000.as.2010, !Geo_FIPS %in% disjoint.tracts)
```

## Normalizing Census Data

```{r}
# Non-iterative normalization; normalizing constants are not updated
survey2000 <- with(census2000.as.2010, data.frame(
  FIPS=Geo_FIPS,
  pop.density=SE_T003_001,
  med.hhold.income=SE_T093_001,
  occupied.housing=SE_T156_001 / SE_T155_001, # Occupied housing units normalized by housing unit count
  owner.occupied=SE_T156_002 / SE_T155_001, # Owner-occupied units normalized by housing unit count
  hholds=SE_T020_001 / SE_T004_002, # Households...by land area
  fam.hholds=SE_T020_002 / SE_T004_002, # Family households...by land area
  married.hholds=SE_T020_003 / SE_T004_002, # Married-couple households...by land area
  lone.male.hholds=SE_T020_005 / SE_T004_002, # Family -holds with lone male householder...by land area
  lone.female.hholds=SE_T020_006 / SE_T004_002, # Family -holds with lone female householder...land area
  male.nonfam.hholds=SE_T020_008 / SE_T004_002, # Non-family -holds with male householder...by land area
  female.nonfam.hholds=SE_T020_009 / SE_T004_002, # Non-family -holds with female householder...land area
  male.pop=SE_T005_002 / SE_T025_001, # Male population normalized by total population
  female.pop=SE_T005_003 / SE_T025_001, # Female population normalized by total pop.
  white.pop=SE_T014_002 / SE_T025_001, # White population...total pop.
  black.pop=SE_T014_003 / SE_T025_001, # Black population...total pop.
  asian.pop=SE_T014_005 / SE_T025_001, # Asian population...total pop.
  poor.pop=SE_T185_004 / SE_T025_001)) # Population poor or struggling...total pop.
survey2006 <- with(acs2006.2010, data.frame(
  FIPS=Geo_FIPS,
  pop.density=SE_T002_001,
  med.hhold.income=SE_T057_001,
  occupied.housing=SE_T094_001 / SE_T093_001, # Occupied housing units normalized by housing unit count
  owner.occupied=SE_T094_002 / SE_T093_001, # Owner-occupied units normalized by housing unit count
  hholds=SE_T017_001 / SE_T002_003, # Households...by land area
  fam.hholds=SE_T017_002 / SE_T002_003, # Family households...by land area
  married.hholds=SE_T017_003 / SE_T002_003, # Married-couple households...by land area
  lone.male.hholds=SE_T017_005 / SE_T002_003, # Family -holds with lone male householder...by land area
  lone.female.hholds=SE_T017_006 / SE_T002_003, # Family -holds with lone female householder...land area
  male.nonfam.hholds=SE_T017_008 / SE_T002_003, # Non-family -holds with male householder...by land area
  female.nonfam.hholds=SE_T017_009 / SE_T002_003, # Non-family -holds with female householder...land area
  male.pop=SE_T004_002 / SE_T001_001, # Male population normalized by total population
  female.pop=SE_T004_003 / SE_T001_001, # Female population normalized by total pop.
  white.pop=SE_T013_002 / SE_T001_001, # White population...total pop.
  black.pop=SE_T013_003 / SE_T001_001, # Black population...total pop.
  asian.pop=SE_T013_005 / SE_T001_001, # Asian population...total pop.
  poor.pop=SE_T118_004 / SE_T001_001)) # Population poor or struggling...total pop.
```

## Preparing a Common Coordinate Reference System

The spatial data need to be transformed to a common projection, [NAD83 UTM zone 17N](http://spatialreference.org/ref/epsg/26917/).

```
gdalwarp -t_srs "EPSG:26917" /home/arthur/Workspace/TermProject/nlcd2001.tif /home/arthur/Workspace/TermProject/nlcd2001_nad83.tif
gdalwarp -t_srs "EPSG:26917" /home/arthur/Workspace/TermProject/nlcd2006.tif /home/arthur/Workspace/TermProject/nlcd2006_nad83.tif
ogr2ogr -f "ESRI Shapefile" -t_srs "EPSG:26917" /usr/local/dev/rdetroit/shp/t10_nad83.shp /usr/local/dev/rdetroit/shp/t10.shp
ogr2ogr -f "ESRI Shapefile" -t_srs "EPSG:26917" /home/arthur/Workspace/TermProject/ancillary/semich_rec_and_outdoor_nad83.shp /home/arthur/Workspace/TermProject/ancillary/semich_rec_and_outdoor.shp
```

## Joining Spatial and Attribute Data

```{r}
# Join census tract shapefiles and census measures
require(rgdal)
tracts <- readOGR('/usr/local/dev/rdetroit/shp/t10_nad83.shp', 't10')
tracts$FIPS <- tracts$GEOID10
tracts <- subset(tracts, select=c('FIPS'))

require(plyr)
attr2000 <- merge(tracts, survey2000, by='FIPS')
attr2006 <- merge(tracts, survey2006, by='FIPS')
```

## Land Cover Data Preparation

```{r data.management, message=FALSE}
library(sp, raster, rgdal)
file.loc <- '/home/arthur/Workspace/TermProject/'

require(raster)
rast <- raster::raster(paste0(file.loc, 'nlcd2006_nad83.tif'))
```

Next, I reclassify the NLCD raster into three classes:

```{r reclass.explication, echo=FALSE}
knitr::kable(data.frame('Input Class Range'=c('[0-10]', '11 (Open Water)', '[12-20]', '[21-23] (Open and Low, Medium Development)', '24 (High Development)', '[25-99]'), 'Output Class'=c(0,NA,0,1,2,0), 'New Class Label'=c('Undeveloped', 'Excluded', 'Undeveloped', 'Low-Intensity Development', 'High-Intensity Development', 'Undeveloped')), col.names=c('Input Class Range', 'Output Class', 'New Class Label'))
```

```{r reclass}
require(raster)
reclass.matrix <- matrix(c(c(0,10,0), c(10,11,NA), c(12,20,0),
                           c(20,23,1), c(23,24,2), c(24,99,0)),
                         byrow=TRUE, ncol=3)
dev <- raster::reclassify(rast, reclass.matrix, right=TRUE) # Intervals closed on right

# Create a smaller sample
ext <- bbox(dev)
dev <- raster::crop(dev, raster::raster(xmn=ext[1], xmx=ext[1] + (ext[3] - ext[1]) * 0.1,
                                         ymn=ext[2], ymx=ext[2] + (ext[4] - ext[2]) * 0.1))
```

## Other Spatial Data Preparation

### Distance to Recreation and Outdoor Areas

```
gdal_rasterize -tr 30 30 -init 0 -burn 1 semich_rec_and_outdoor_nad83.shp semich_rec_and_outdoor_nad83.tiff
gdal_proximity.py -values 1 semich_rec_and_outdoor_nad83.tiff semich_rec_and_outdoor_proximity.tiff
```

If using the recreation areas as a binary map...

```{r eval=FALSE}
require(sp, raster)

# Recreation and outdoor areas
rec.areas <- readOGR(paste0(file.loc, 'ancillary/semich_rec_and_outdoor_nad83.shp'),
                     'semich_rec_and_outdoor_nad83')

# Raster and vector layers have just SLIGHTLY different projection definitions...
rec.areas <- sp::spTransform(rec.areas, raster::crs(dev2000))

# Subset to just those areas in the tri-county extent of interest
rec.areas <- subset(rec.areas, COUNTY %in% c(125, 99, 163), select='TYPE')

rec2000 <- sp::over(devp2000, rec.areas)

# Reclassify the recreation area data to a binary map
rec2000[is.na(rec2000)] <- 0
rec2000$TYPE[rec2000$TYPE==8] <- 1
names(rec2000) <- c('rec.area')

# Again, the number of points is different in practice
rec2006 <- data.frame(rec.area=matrix(nrow=dim(attr2006)[1], ncol=1)) # Copy
rec2006 <- mutate(rec2006, rec.area=c(rec2000$rec.area, rep(NA, dim(attr2006)[1] - dim(rec2000)[1])))
```

### Distance to Roads

Using the [MI Geographic Framework All Roads (v14a) from MiGDL](http://www.mcgi.state.mi.us/mgdl/?rel=thext&action=thmname&cid=14&cat=MI+Geographic+Framework+All+Roads+%28v14a%29) as the source layer...

```
# Filter road types to primary roads and clip the roads layer to a WKT bounding box, setting the output to GCS WGS84 so that a WKT bounding box is acceptable
ogr2ogr -skipfailures -f "ESRI Shapefile" -where "NFC IN (1,2,3)" -clipdst "POLYGON((-82.35 42.95,-82.35 41.75,-84.11 41.75,-84.11 42.95,-82.35 42.95))" -t_srs "EPSG:4326" semich_roads_wgs84.shp allroads_miv14a.shp

# Transforming back into UTM (linear units must be meters for next step)
ogr2ogr -f "ESRI Shapefile" -t_srs "EPSG:26917" semich_roads_nad83.shp semich_roads_wgs84.shp

# Rasterizing the roads layer and then making a proximity map
gdal_rasterize -tr 30 30 -init 0 -burn 1 semich_roads_nad83.shp roads.tiff
gdal_proximity.py roads.tiff roads_proximity.tiff -values 1
```

## Spatial Join of Census Measures and Land Cover Data

```{r}
library(sp, raster, rgdal)
# Match the projection of the land cover layer
# attr2000 <- spTransform(attr2000, raster::crs(dev))

# "Sample" the census data by the land cover grid; of course, due to package limitations the raster's value is not included in this "spatial join"
devp <- raster::rasterToPoints(dev, spatial=TRUE)
t2000 <- sp::over(devp, attr2000)

# Assume that the rows are in order; we align the land cover pixels with the attributes we just sampled
# (Naive, but R leaves us with no choice)
require(plyr)
train2000 <- cbind(data.frame(cover=devp$layer), t2000)

# Add class labels
# train2000$cover <- factor(train2000$cover,
#                           labels=c('undeveloped', 'low-development', 'high-development'))
# cover2006$cover <- factor(cover2006$cover,
#                           labels=c('undeveloped', 'low-development', 'high-development'))
```

## Configuring and Learning on the Bayesian Network

The conditional probability table (CPT) will be populated through learning by maximum likelihood estimation (MLE) after Kocabas and Dragicevic (2007).

```{r}
vars <- c('cover', 'T003_001', 'T093_001', 'T156_001', 'T156_002', 'T020_002', 'T185_004')
pdag2000 <- bnlearn::iamb(train2000[,(names(train2000) %in% vars[1:i])])
```

### Timing

We'll initially time the learning as we expect it to take a long time. For Incremental Association Markov Blanket (IAMB), Scutari (2014) estimates it will execute in $O(N^2)$ time or, "in the worst case," $(O(N^4)$ time.

```{r eval=FALSE}
require(bnlearn)
l.params <- c()
l.iamb <- c()
l.fast.iamb <- c()
vars <- c('cover', 'T003_001', 'T093_001', 'T155_001', 'T156_002', 'T025_013', 'T020_001', 'T020_002', 'T020_003', 'T025_006')

# Timings on a 64-bit Intel® Core™ i7-2600 CPU @ 3.40GHz × 8 with 7.8 GB memory
for (i in seq(3, length(vars), by=1)) {
  for (j in c(1,2,3)) {
    ptm <- proc.time() # Start the clock!
    pdag2000 <- bnlearn::iamb(train2000[,(names(train2000) %in% vars[1:i])])
    i.elapsed <- proc.time() - ptm # Stop the clock
    
    ptm <- proc.time() # Start the clock!
    pdag2000 <- bnlearn::fast.iamb(train2000[,(names(train2000) %in% vars[1:i])])
    fi.elapsed <- proc.time() - ptm # Stop the clock
    
    l.params <- c(l.params, length(vars[1:i]))
    l.iamb <- c(l.iamb, as.numeric(i.elapsed['elapsed']))
    l.fast.iamb <- c(l.fast.iamb, as.numeric(fi.elapsed['elapsed']))
  }
}
```

```{r}
par(mfrow=c(1,2))
plot(l.params, l.fast.iamb, log='y', xlab='Number of parameters, N', ylab='log10 Time in seconds')
title('Fast IAMB Network Learning')
plot(l.params, l.iamb, log='y', xlab='Number of parameters, N', ylab='log10 Time in seconds')
title('IAMB Network Learning')
par(mfrow=c(1,1))
```

As the curves appear to be straight lines on the log-linear plot, we can assume a function that fits these data takes the form $a + b^x$ where the slope of the curve is given by the base-10 logarithm of $b$.

```{r}
require(plyr)
timings <- data.frame(n=l.params, iamb=l.iamb)

# Try an exponential model of timing
expmod <- lm(log10(iamb) ~ n, data=timings)
quadmod <- lm(iamb ~ n + I(n^2), data=timings)

require(ggplot2)
ggplot() +
  geom_point(timings, mapping=aes(x=n, y=iamb), pch='+', size=7) +
  stat_function(data=data.frame(x=seq(1, 9, by=1)),
                fun=function (n) { coef(quadmod)['(Intercept)'] +
                                     (coef(quadmod)['n'] * n) + (coef(quadmod)['I(n^2)'] * n^2)},
                lty='dashed') +
  stat_function(data=data.frame(x=seq(1, 9, by=1)),
                fun=function (n) { 10^(coef(expmod)['(Intercept)'] + coef(expmod)['n'] * n) },
                lty='solid') +
  labs(title='Two models for scaling of IAMB time with parameters') +
  xlab('Number of parameters, N') +
  ylab('Time for IAMB (seconds)') +
  theme_bw() +
  theme(text=element_text(size=14))
```

The quadratic model fits just slightly better than the exponential model, although this may be just because it has an extra parameter.

```{r}
summary(quadmod)
summary(expmod)
```

We could use AIC to compare the two models but the difference is small and likely less than the critical difference required to be significant. The AIC for the exponential model is `{r} as.numeric((2 * 3) - 2*log(logLik(expmod)))`; for the quadratic model it is `{r} as.numeric((2 * 4) - 2*log(logLik(quadmod)))`. At the 95% confidence interval, these models are still very close, with the critical value from the chi-squared distribution being `{r} qchisq(p=0.95, df=1)/2` and the actual difference between the models being `{r} as.numeric((2 * 3) - 2*log(logLik(expmod))) - as.numeric((2 * 4) - 2*log(logLik(quadmod)))`.

In summary, there really isn't enough data to discriminate between them, so we're obliged to go with the quadratic time model as this is supported in the literature. The predictions show that we should be able to train a network with up to 20 parameters in under 10 seconds. Thus, any training that takes significantly longer than this amount of time is likely due to errors encountered by the learning algorithm, such as correlated root nodes.

```{r}
predict(quadmod, data.frame(n=seq(1, length(census.vars), by=1)))
```

# Questions

* Can I do network learning in parallel with the `parallel` package and `makeCluster` (see Page 4, http://cran.r-project.org/web/packages/bnlearn/bnlearn.pdf)?
* What network learning algorithm is most efficient and produces the best results (or is the best trade-off between speed and accuracy)?
* What census tract boundaries are used in the American Community Survey? \textbf{The 2010 tract boundaries are used.} [(Source)](http://www.census.gov/geo/maps-data/data/pdfs/tiger/How_do_I_choose_TIGER_vintage.pdf)

# References

1. Scutari, M. (2014). bnlearn R Package Documentation. Retrieved November 12, 2014, from http://cran.r-project.org/web/packages/bnlearn/bnlearn.pdf




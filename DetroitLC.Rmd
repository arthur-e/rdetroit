---
title: "Detroit Metro Land Cover Data"
author: "K. Arthur Endsley"
date: "Wednesday, November 05, 2014"
output: pdf_document
---

The intent is to learn the major drivers of land cover change in the Detroit Metro area from 2001 to 2006 and use the modeled relationships to predict land cover change in 2011.

# Data Sources

All dollar values were adjusted for inflation to 2010 values. County boundaries used for subsetting data came from [the U.S. Census TIGER dataset](https://www.census.gov/geo/maps-data/data/cbf/cbf_counties.html).

**Used in analysis:**
* [2000 and 2010 Census tract boundaries](http://semcog.org/MapCatalog_Demographic.aspx) - SEMCOG

**Alternatives:** 
* [2000 Census tract boundaries](http://www.mcgi.state.mi.us/mgdl/?rel=thext&action=thmname&cid=16&cat=2000+Tracts+from+MI+Geographic+Framework+%28v14a%29)
* [2010 Census tract boundaries](http://www.mcgi.state.mi.us/mgdl/?rel=thext&action=thmname&cid=16&cat=2010+Tracts+from+MI+Geographic+Framework+%28v14a%29) (Used for 2006 ACS as well)

## Potential SocialExplorer Census Measures

Variable names are given in parentheses as (2000 Census, 2010 Census, American Community Survey 2006-2010, ACS 2008-2012).

* Population density (`T003_001`, `T002_002`, `T002_002`, `T002_002`)
* Median household income (`T093_001`, (None), `T057_001`, `T057_001`)

* Normalized by housing unit count (`T155_001`, `T068_001`, `T093_001`, `T093_001`)...
  * Occupied housing units (`T156_001`, `T069_001`, `T094_001`, `T094_001`)
  * Occupied housing units: owner occupied (`T156_002`, `T069_002`, `T094_002`, `T094_002`)

* Normalized by land area (`T004_002`, `T002_006`, `T002_003`, `T002_003`)...
  * Housing unit count (`T155_001`, `T068_001`, `T093_001`, `T093_001`)
  * Households (`T020_001`, `T058_001`, `T017_001`, `T017, 001`)
  * Family households (`T020_002`, `T058_002`, `T017_002`, `T017_002`)
  * Married-couple households (`T020_003`, `T058_003`, `T017_003`, `T017_003`)
  * Family households with Male householder, no spouse present (`T020_005`, `T058_005`, `T017_005`, `T017_005`)
  * Family households with Female householder, no spouse present (`T020_006`, `T058_006`, `T017_006`,
  `T017_006`)
  * Non-family households with Male householder (`T020_008`, (None), `T017_008`, `T017_008`)
  * Non-family households with Female householder (`T020_009`, (None), `T017_009`, `T017_009`)
  
* Normalized by family household population (`T025_003`, `T063_003`, (None), (None))...
  * Householders (`T025_004`, `T063_004`, (None), (None))
  * Children in households (`T025_006`, `T063_006`, (None), (None))
  * Grandchildren in households (`T025_007`, `T063_007`, (None), (None))
  * Parents in households (`T025_009`, `T063_009`, (None), (None))
  * Non-relatives in households (`T025_011`, `T063_011`, (None), (None))
  
* Normalized by non-family household population (`T025_012`, `T063_012`, (None), (None))...
  * Population living alone (`T025_013`, `T063_013`, (None), (None))
  
* Normalized by total population (`T025_001`, `T055_001`, `T001_001`, `T001_001`)...
  * Male population (`T005_002`, `T003_002`, `T004_002`, `T004_002`)
  * Female population (`T005_003`, `T003_003`, `T004_003`, `T004_002`)
  * White population (`T014_002`, `T054_002`, `T013_002`, `T013_002`)
  * Black or African American population (`T014_003`, `T054_003`, `T013_003`, `T013_003`)
  * Asian population (`T014_005`, `T054_005`, `T013_005`, `T013_005`)
  * Population in group quarters (`T025_016`, `T063_016`, (None), (None))
  * Population 16 years and over (`T069_001`, (None), (None), (None))
  * Population poor or struggling (`T185_004`, (None), `T118_004`, `T118_004`)

* Normalized by population in group quarters (`T025_016`, `T063_016`, (None), (None))...
  * Institutionalized population (`T025_017`, (None), (None), (None))
  
* Normalized by population 16 years and over (`T069_001`, (None), (None), (None))...
  * Population 16 and over in the labor force (`T069_002`, (None), (None), (None))
  
* Normalized by population 16 and over in the labor force (`T069_002`, (None), (None), (None))...
  * Employed civilians in the labor force (`T069_005`, (None), (None), (None))

## U.S. Census

* [Decennial Census overview and 1990, 2000 datasets](http://www.census.gov/prod/www/decennial.html)
* [Maps and geographic data](http://www.census.gov/geo/maps-data/)

# Methodology

1. Interpolate 2000 Census data to 2010 Census tract boundaries.
2. Normalize 2000 Census and ACS 2006 measures.
3. Join census tract attributes to census tract boundaries.
4. Project land cover and landscape measures to a common UTM projection (17N).
  - Distance to roads (from Michigan roads layer via MiGDL)
  - Distance to [recreation and open space](ftp://ftp.semcog.org/outgoing/web/landuse/regrec.zip)
5. Calculate proximity to roads, proximity to recreation and open space.
6. Reclassify land cover to open, low-intensity, and high-intensity development.
7. Spatially join land cover data with census and landscape measures.
8. Discretize the predictor data.
9. Creating a training data subset.
10. Learn the Bayesian network structure.
  - Compare learned network structure across constraint-based, score-based and hybrid structure learning algorithms.
  - Compare learned network structure for 2001 data (only) and 2006 data (only) using Bayes Information Criterion (`bnlearn::score()`).
  - Use random restarts and perturbation with the Hill Climbing algorithm to determine stability of learned and expert-specified network structures.
  - Learn network only on changed pixels from 2001 to 2006.
  - Construct random undirected graph.
  - Construct expert undirected graph.
11. Parameterize the nodes of the BN.
12. Discretize the predictor variable layers.
13. Investigate the effect of monotonic changes in population density, medium household income, and (proportion) occupied housing on land cover.
14. Evaluate best model's performance through three different training configurations:
  - Combined 2001-2006 census and land cover observations
  - Only changed 2001-2006 pixels.
  - Reserving half of combined 2001-2006 data for out-of-fit prediction.
15. Check effects of scale on training the Bayesian network.
  - Go back and train the network on the same data aggregated to 300 meters.

## Dependencies

```{r installation, eval=FALSE}
install.packages(c('bnlearn', 'reshape2', 'plyr', 'ggplot2', 'sp',
                   'raster', 'rgdal', 'RColorBrewer', 'parallel', 'irr'))

# We have to use Bioconductor to install gRain dependencies
source('http://bioconductor.org/biocLite.R')
biocLite('graph')
biocLite('RBGL')

install.packages('gRain')
```

## Preparing a Common Coordinate Reference System

We'll use the census tracts as cutline features.

```
mkdir -p /usr/local/dev/rdetroit/shp && cd /usr/local/dev/rdetroit/shp
wget ftp://ftp.semcog.org/outgoing/web/demographic/regtrct00.zip
wget ftp://ftp.semcog.org/outgoing/web/demographic/regtrct10.zip
unzip regtrct00.zip
unzip regtrct10.zip
ogr2ogr -f "ESRI Shapefile" -where "COUNTY=99 OR COUNTY=125 OR COUNTY=163" t10.shp regtrct10.shp
ogr2ogr -f "ESRI Shapefile" -where "COUNTY=99 OR COUNTY=125 OR COUNTY=163" t00.shp regtrc00.shp
rm *.zip
rm regtrct10.*
rm regtrc00.*
ogr2ogr -f "ESRI Shapefile" -t_srs "EPSG:26917" /usr/local/dev/rdetroit/shp/t10_nad83.shp /usr/local/dev/rdetroit/shp/t10.shp
```

The spatial data need to be transformed to a common projection, [NAD83 UTM zone 17N](http://spatialreference.org/ref/epsg/26917/).

```
FILE_LOC=/home/arthur/Workspace/TermProject/
gdalwarp -t_srs "EPSG:26917" -cutline /usr/local/dev/rdetroit/shp/t10_nad83.shp -cl "t10_nad83" -crop_to_cutline $FILE_LOC/nlcd2001.tif $FILE_LOC/nlcd2001_nad83.tif
gdalwarp -t_srs "EPSG:26917" -cutline /usr/local/dev/rdetroit/shp/t10_nad83.shp -cl "t10_nad83" -crop_to_cutline $FILE_LOC/nlcd2006.tif $FILE_LOC/nlcd2006_nad83.tif

wget http://www2.census.gov/geo/tiger/PREVGENZ/co/co00shp/co26_d00_shp.zip
unzip co26_d00_shp.zip
ogr2ogr -f "ESRI Shapefile" -s_srs "EPSG:4269" -t_srs "EPSG:4269" -where "COUNTY IN ('099', '125', '163')" $FILE_LOC/ancillary/co26_d00_select.shp $FILE_LOC/ancillary/co26_d00.shp
ogr2ogr -f "ESRI Shapefile" -t_srs "EPSG:26917" $FILE_LOC/ancillary/co26_d00_select_nad83.shp $FILE_LOC/ancillary/co26_d00_select.shp
```

### Distance to Recreation and Outdoor Areas

Recreation and outdoor areas provided by SEMCOG [via this link](ftp://ftp.semcog.org/outgoing/web/landuse/regrec.zip).

```
FILE_LOC=/home/arthur/Workspace/TermProject/ancillary

wget ftp://ftp.semcog.org/outgoing/web/landuse/regrec.zip
unzip regrec.zip

# Project the Shapefile
ogr2ogr -f "ESRI Shapefile" -t_srs "EPSG:26917" $FILE_LOC/rec+outdoor_nad83.shp $FILE_LOC/regrec.shp

# Rasterize, calculate proximity, and cut to the census tracts extent
gdal_rasterize -tr 30 30 -init 0 -burn 1 $FILE_LOC/rec+outdoor_nad83.shp $FILE_LOC/rec+outdoor_nad83.tiff
gdal_proximity.py -values 1 $FILE_LOC/rec+outdoor_nad83.tiff $FILE_LOC/rec+outdoor_nad83_prox.tiff
gdalwarp -t_srs "EPSG:26917" -cutline /usr/local/dev/rdetroit/shp/t10_nad83.shp -cl "t10_nad83" -crop_to_cutline $FILE_LOC/rec+outdoor_nad83_prox.tiff $FILE_LOC/rec+outdoor_nad83_prox_cut.tiff
```

### Distance to Roads

Using the [MI Geographic Framework All Roads (v14a) from MiGDL](http://www.mcgi.state.mi.us/mgdl/?rel=thext&action=thmname&cid=14&cat=MI+Geographic+Framework+All+Roads+%28v14a%29) as the source layer...

```
# Filter road types to primary roads and clip the roads layer to a WKT bounding box, setting the output to GCS WGS84 so that a WKT bounding box is acceptable
ogr2ogr -skipfailures -f "ESRI Shapefile" -where "NFC IN (1,2,3)" -clipdst "POLYGON((-82.35 42.95,-82.35 41.75,-84.11 41.75,-84.11 42.95,-82.35 42.95))" -t_srs "EPSG:4326" $FILE_LOC/semich_roads_wgs84.shp $FILE_LOC/allroads_miv14a.shp

# Transforming back into UTM (linear units must be meters for next step)
ogr2ogr -f "ESRI Shapefile" -t_srs "EPSG:26917" $FILE_LOC/semich_roads_nad83.shp $FILE_LOC/semich_roads_wgs84.shp

# Rasterizing the roads layer and then making a proximity map
gdal_rasterize -tr 30 30 -init 0 -burn 1 $FILE_LOC/semich_roads_nad83.shp $FILE_LOC/roads.tiff
gdal_proximity.py $FILE_LOC/roads.tiff $FILE_LOC/roads_proximity.tiff -values 1

gdalwarp -t_srs "EPSG:26917" -cutline /usr/local/dev/rdetroit/shp/t10_nad83.shp -cl "t10_nad83" -crop_to_cutline $FILE_LOC/roads_proximity.tiff $FILE_LOC/roads_proximity_cut.tiff
```

## Cross-Walking Census Data

From [U.S. 2010: Discover America in a New Century](http://www.s4.brown.edu/us2010/Researcher/ltdb3.htm): "The crosswalk identifies what portion of a tract in one year should be allocated to a 2010 tract. For every decennial year from 1970 to 2000, every row in the crosswalk lists a 2010 tract ID, the ID of a tract in the source year that contributes to it, and the share of the source tract's population attributes that should be allocated to the 2010 tract. In cases where there is an exact correspondence between the source tract and the 2010 tract, there is only one row of data for the 2010 tract. Otherwise there are as many rows as there are contributing tracts."

## Interpolating 2000 Census Tracts to 2010 Census Tracts

```{r preamble, warning=FALSE, results=FALSE, message=FALSE}
library(sp, raster)
library(rgdal)
library(plyr, reshape2)
library(bnlearn)

setwd('/usr/local/dev/rdetroit/')
options(stringsAsFactors=FALSE)
```

```{r}
census2000 <- read.csv('census_data/census2000.csv', header=T, skip=1,
                       colClasses=c('Geo_FIPS'='character')) # 2000 Census data
acs2006.2010 <- read.csv('census_data/acs2006-2010.csv', header=T, skip=1,
                         colClasses=c('Geo_FIPS'='character')) # 2006-2010 ACS data
xwalk <- plyr::arrange(read.csv('census_data/crosswalk_2000_2010.csv',
                                colClasses=c('character', 'character')),
                 trtid10) # 2000 to 2010 Crosswalk data
xwalk <- within(xwalk, weight <- as.numeric(weight))

require(plyr)
census2000 <- subset(mutate(census2000, trtid00=Geo_FIPS), select=c('trtid00', census.vars))
acs2006.2010 <- subset(acs2006.2010, select=c('Geo_FIPS', acs.vars))

# Subset the crosswalk table to just those tracts in our census data
xwalk <- subset(xwalk, trtid00 %in% intersect(census2000$trtid00, xwalk$trtid00),
                select=c(trtid00, trtid10, weight))

# We interpolate the 2000 census tracts to 2010 census tracts by a weighted linear combination
require(reshape2)
temp <- melt(join(xwalk, census2000, by=c('trtid00')),
             id.vars=c('trtid00', 'trtid10', 'weight'))
temp <- within(temp, value <- value * weight) # Scale the census measures by Brown et al.'s weights

# Recast 2010 census tracts as a sum of the 2000 census measures
census2000.as.2010 <- within(dcast(temp, trtid10 ~ variable, fun.aggregate=sum, value.var='value'), Geo_FIPS <- trtid10)

# For some reason, a couple of tracts in the ACS are not in the 2010 interpolation of the 2000 census
disjoint.tracts <- union(setdiff(census2000.as.2010$Geo_FIPS, acs2006.2010$Geo_FIPS),
                         setdiff(acs2006.2010$Geo_FIPS, census2000.as.2010$Geo_FIPS))

acs2006.2010 <- subset(acs2006.2010, !Geo_FIPS %in% disjoint.tracts)
census2000.as.2010 <- subset(census2000.as.2010, !Geo_FIPS %in% disjoint.tracts)

require(ggplot2)
ggplot(data=melt(census2000.as.2010, id.vars=c('trtid10', 'Geo_FIPS')),
                 mapping=aes(x=value, group=variable)) +
  geom_histogram() +
  facet_wrap(~ variable, scales='free')
```

## Normalizing Census Data

```{r}
survey2000 <- with(census2000.as.2010, data.frame(
  FIPS=Geo_FIPS,
  pop.density=SE_T003_001,
  med.hhold.income=SE_T093_001,
  occupied.housing=SE_T156_001 / SE_T155_001, # Occupied housing units norm. by housing unit count
  owner.occupied=SE_T156_002 / SE_T155_001, # Owner-occupied units...by housing unit count
  hholds=SE_T020_001 / SE_T004_002, # Households...by land area
  fam.hholds=SE_T020_002 / SE_T004_002, # Family households...by land area
  married.hholds=SE_T020_003 / SE_T004_002, # Married-couple households...by land area
  lone.male.hholds=SE_T020_005 / SE_T004_002, # Family -holds w/ lone male h-holder...by land area
  lone.female.hholds=SE_T020_006 / SE_T004_002, # Fam. -holds w/ lone female h-holder...land area
  male.nonfam.hholds=SE_T020_008 / SE_T004_002, # Non-fam. -holds w/ male h-holder...by land area
  female.nonfam.hholds=SE_T020_009 / SE_T004_002, # Non-fam. -holds w/ female h-holder...land area
  male.pop=SE_T005_002 / SE_T025_001, # Male population normalized by total population
  female.pop=SE_T005_003 / SE_T025_001, # Female population normalized by total pop.
  white.pop=SE_T014_002 / SE_T025_001, # White population...total pop.
  black.pop=SE_T014_003 / SE_T025_001, # Black population...total pop.
  asian.pop=SE_T014_005 / SE_T025_001, # Asian population...total pop.
  poor.pop=SE_T185_004 / SE_T025_001)) # Population poor or struggling...total pop.
survey2006 <- with(acs2006.2010, data.frame(
  FIPS=Geo_FIPS,
  pop.density=SE_T002_002, # FIXME Oops!
  med.hhold.income=SE_T057_001,
  occupied.housing=SE_T094_001 / SE_T093_001, # Occupied housing units norm. by housing unit count
  owner.occupied=SE_T094_002 / SE_T093_001, # Owner-occupied units norm. by housing unit count
  hholds=SE_T017_001 / SE_T002_003, # Households...by land area
  fam.hholds=SE_T017_002 / SE_T002_003, # Family households...by land area
  married.hholds=SE_T017_003 / SE_T002_003, # Married-couple households...by land area
  lone.male.hholds=SE_T017_005 / SE_T002_003, # Family -holds w/ lone male h-holder...by land area
  lone.female.hholds=SE_T017_006 / SE_T002_003, # Fam. -holds w/ lone female h-holder...land area
  male.nonfam.hholds=SE_T017_008 / SE_T002_003, # Non-fam. -holds w/ male h-holder...by land area
  female.nonfam.hholds=SE_T017_009 / SE_T002_003, # Non-fam. -holds w/ female h-holder...land area
  male.pop=SE_T004_002 / SE_T001_001, # Male population normalized by total population
  female.pop=SE_T004_003 / SE_T001_001, # Female population normalized by total pop.
  white.pop=SE_T013_002 / SE_T001_001, # White population...total pop.
  black.pop=SE_T013_003 / SE_T001_001, # Black population...total pop.
  asian.pop=SE_T013_005 / SE_T001_001, # Asian population...total pop.
  poor.pop=SE_T118_004 / SE_T001_001)) # Population poor or struggling...total pop.

# Clean-up
remove(acs2006.2010, census2000, census2000.as.2010, temp)
```

## Joining Spatial and Attribute Data

```{r}
# Join census tract shapefiles and census measures
require(rgdal)
tracts <- readOGR('/usr/local/dev/rdetroit/shp/t10_nad83.shp', 't10_nad83')
tracts$FIPS <- tracts$GEOID10
tracts <- subset(tracts, select=c('FIPS'))

require(plyr)
attr2000 <- merge(tracts, survey2000, by='FIPS')
attr2006 <- merge(tracts, survey2006, by='FIPS')
```

## Land Cover Data Preparation

```{r data.management, message=FALSE}
file.loc <- '/home/arthur/Workspace/TermProject/'

require(raster)
rast2000 <- raster::raster(paste0(file.loc, 'nlcd2001_nad83.tif'))
rast2006 <- raster::raster(paste0(file.loc, 'nlcd2006_nad83.tif'))

plot(rast2000)
plot(rast2006)
```

Next, I reclassify the NLCD raster into three classes:

```{r reclass.explication, echo=FALSE}
knitr::kable(data.frame('Input Class Range'=c('[0-10]', '11 (Open Water)', '[12-20]', '[21-23] (Open and Low, Medium Development)', '24 (High Development)', '[25-99]'), 'Output Class'=c(0,NA,0,1,2,0), 'New Class Label'=c('Undeveloped', 'Excluded', 'Undeveloped', 'Low-Intensity Development', 'High-Intensity Development', 'Undeveloped')), col.names=c('Input Class Range', 'Output Class', 'New Class Label'))
```

```{r reclass}
require(raster)
reclass.matrix <- matrix(c(c(0,10,0), c(10,11,NA), c(12,20,0),
                           c(20,23,1), c(23,24,2), c(24,99,0)),
                         byrow=TRUE, ncol=3)
dev2000 <- raster::reclassify(rast2000, reclass.matrix, right=TRUE) # Intervals closed on right
dev2006 <- raster::reclassify(rast2006, reclass.matrix, right=TRUE)
```

## Other Spatial Data Preparation

```{r}
file.loc <- '/home/arthur/Workspace/TermProject/'

# Recreation and outdoor areas
rec.area.proximity <- raster::raster(paste0(file.loc,
                                            'ancillary/rec+outdoor_nad83_prox_cut.tiff'))
plot(rec.area.proximity)

# Distance to primary roads
road.proximity <- raster::raster(paste0(file.loc, 'ancillary/roads_proximity_cut.tiff'))
plot(road.proximity)
```

## Configuring and Learning on the Bayesian Network

The conditional probability table (CPT) will be populated through learning by maximum likelihood estimation (MLE) after Kocabas and Dragicevic (2007).

```{r}
load(file='rda/training.rda')
```

### Timing

We'll initially time the learning as we expect it to take a long time. For Incremental Association Markov Blanket (IAMB), Scutari (2014) estimates it will execute in $O(N^2)$ time or, "in the worst case," $(O(N^4)$ time.

```{r eval=FALSE}
require(bnlearn)
l.params <- c()
l.iamb <- c()
l.fast.iamb <- c()
vars <- c('old', 'new', 'road.proximity', 'rec.area.proximity', 'married.hholds', 'med.hhold.income', 'pop.density', 'male.pop')
training.data <- subset(training, select=vars)
training.sample <- training.data[sample(nrow(training.data),
                                        dim(training.data)[1]*0.05),]

# Timings on a 64-bit Intel® Core™ i7-2600 CPU @ 3.40GHz × 8 with 7.8 GB memory
for (i in seq(3, length(vars), by=1)) {
  for (j in c(1,2,3)) {
    ptm <- proc.time() # Start the clock!
    pdag <- bnlearn::iamb(training.sample[,(names(training.sample) %in% vars[1:i])])
    i.elapsed <- proc.time() - ptm # Stop the clock
    
    ptm <- proc.time() # Start the clock!
    pdag <- bnlearn::fast.iamb(training.sample[,(names(training.sample) %in% vars[1:i])])
    fi.elapsed <- proc.time() - ptm # Stop the clock
    
    l.params <- c(l.params, length(vars[1:i]))
    l.iamb <- c(l.iamb, as.numeric(i.elapsed['elapsed']))
    l.fast.iamb <- c(l.fast.iamb, as.numeric(fi.elapsed['elapsed']))
  }
}
```

```{r}
par(mfrow=c(1,2))
plot(l.params, l.fast.iamb, log='y', xlab='Number of parameters, N', ylab='log10 Time in seconds')
title('Fast IAMB Network Learning')
plot(l.params, l.iamb, log='y', xlab='Number of parameters, N', ylab='log10 Time in seconds')
title('IAMB Network Learning')
par(mfrow=c(1,1))
```

As the curves appear to be straight lines on the log-linear plot, we can assume a function that fits these data takes the form $a + b^x$ where the slope of the curve is given by the base-10 logarithm of $b$.

```{r}
require(plyr)
timings <- data.frame(n=l.params, iamb=l.iamb)

# Try an exponential model of timing
expmod <- lm(log10(iamb) ~ n, data=timings)
quadmod <- lm(iamb ~ n + I(n^2), data=timings)

require(ggplot2)
ggplot() +
  geom_point(timings, mapping=aes(x=n, y=iamb), pch='+', size=7) +
  stat_function(data=data.frame(x=seq(1, 9, by=1)),
                fun=function (n) { coef(quadmod)['(Intercept)'] +
                                     (coef(quadmod)['n'] * n) + (coef(quadmod)['I(n^2)'] * n^2)},
                lty='dashed') +
  stat_function(data=data.frame(x=seq(1, 9, by=1)),
                fun=function (n) { 10^(coef(expmod)['(Intercept)'] + coef(expmod)['n'] * n) },
                lty='solid') +
  labs(title='Two models for scaling of IAMB time with parameters') +
  xlab('Number of parameters, N') +
  ylab('Time for IAMB (seconds)') +
  theme_bw() +
  theme(text=element_text(size=14))
```

The exponential model fits just slightly better than the quadratic model despite the latter having an extra parameter.

```{r}
summary(quadmod)
summary(expmod)
```

We could use AIC to compare the two models but the difference is small and likely less than the critical difference required to be significant. The AIC for the exponential model is `r as.numeric((2 * 3) - 2*log(logLik(expmod)))`; for the quadratic model it is `r as.numeric((2 * 4) - 2*log(logLik(quadmod)))`. At the 95% confidence interval, these models are still very close, with the critical value from the chi-squared distribution being `r qchisq(p=0.95, df=1)/2` and the actual difference between the models being `r as.numeric((2 * 3) - 2*log(logLik(expmod))) - as.numeric((2 * 4) - 2*log(logLik(quadmod)))`.

In summary, there really isn't enough data to discriminate between them, so we're obliged to go with the quadratic time model as this is supported in the literature. The predictions show that we should be able to train a network with up to 20 parameters in under 10 seconds. Thus, any training that takes significantly longer than this amount of time is likely due to errors encountered by the learning algorithm, such as correlated root nodes.

```{r}
predict(quadmod, data.frame(n=seq(1, length(census.vars), by=1)))
```

# Improvements

* In the discretization, the predictor variables should be discretized to factors that match those factors expected by the Bayesian Network. This will speed up predictions and allow for even multi-threaded prediction.

# Questions

* Can I do network learning in parallel with the `parallel` package and `makeCluster` (see Page 4, http://cran.r-project.org/web/packages/bnlearn/bnlearn.pdf)?
* What census tract boundaries are used in the American Community Survey? \textbf{The 2010 tract boundaries are used.} [(Source)](http://www.census.gov/geo/maps-data/data/pdfs/tiger/How_do_I_choose_TIGER_vintage.pdf)

# References

1. John R. Logan, Zengwang Xu, and Brian Stults. 2012. "Interpolating US Decennial Census Tract Data from as Early as 1970 to 2010: A Longitudinal Tract Database" Professional Geographer, forthcoming.
2. Nagarajan, R., Scutari, M., & Lebre, S. (2013). Bayesian Networks in R. New York, New York, USA: Springer. Retrieved from http://link.springer.com/content/pdf/10.1007/978-1-4614-6446-4.pdf
3. Scutari, M. (2014). bnlearn R Package Documentation. Retrieved November 12, 2014, from http://cran.r-project.org/web/packages/bnlearn/bnlearn.pdf



